{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[u'percent', u'business', u'company', u'points', u'companies', u'businesses', u'york', u'stocks', u'sales', u'rico', u'workers', u'puerto', u'index', u'quarter', u'power', u'oil', u'mobile', u'sprint', u'share', u'island']\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from operator import add\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"advertisement\")\n",
    "stop_words.add(\"said\")\n",
    "stop_words.add(\"\")\n",
    "stop_words.add(\" \")\n",
    "stop_words.add(\"  \")\n",
    "stop_words.add(\"ms\")\n",
    "stop_words.add(\"house\")\n",
    "stop_words.add(\"brown\")\n",
    "stop_words.add(\"people\")\n",
    "stop_words.add(\"news\")\n",
    "stop_words.add(\"states\")\n",
    "stop_words.add(\"week\")\n",
    "stop_words.add(\"photo\")\n",
    "stop_words.add(\"diaz\")\n",
    "stop_words.add(\"year\")\n",
    "stop_words.add(\"years\")\n",
    "stop_words.add(\"time\")\n",
    "stop_words.add(\"state\")\n",
    "stop_words.add(\"states\")\n",
    "stop_words.add(\"women\")\n",
    "stop_words.add(\"trade\")\n",
    "stop_words.add(\"kan\")\n",
    "\n",
    "filepath = \"/Users/mahalakshmimaddu/Desktop/DICLab3/Part2/CleanedFiles/Business/\"\n",
    "\n",
    "for file in os.listdir(filepath):\n",
    "        textRDD = sc.textFile(filepath)\n",
    "        words = textRDD.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1))\n",
    "        wordcount = words.reduceByKey(add).collect()\n",
    "output = sorted(wordcount, key = lambda x:x[1], reverse=True)\n",
    "\n",
    "top_words = []\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "\n",
    "i = 0;\n",
    "x = 0;\n",
    "while x < len(output) and i < 20:\n",
    "    word = [output[x][0].encode('ascii','ignore')]\n",
    "    if(bool(word[0].strip())):\n",
    "        l1 =  nltk.tag.pos_tag(word)\n",
    "        if ((is_noun(l1[0][1])) and (not (word[0].lower() in (stop_words))) and len(word[0]) > 2):\n",
    "            top_words.append(output[x][0])\n",
    "            i = i+1;\n",
    "            x = x+1;\n",
    "        else:\n",
    "            x = x+1;\n",
    "    else:\n",
    "        x = x+1;\n",
    "print(str(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['percent', 'business', 'company', 'points', 'companies', 'businesses', 'york', 'stocks', 'sales', 'rico', 'workers', 'puerto', 'index', 'quarter', 'power', 'oil', 'mobile', 'sprint', 'share', 'island']\n"
     ]
    }
   ],
   "source": [
    "new_words = []\n",
    "for i in range(len(top_words)):\n",
    "    new_words.append(top_words[i].encode('utf-8'))\n",
    "print(str(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
