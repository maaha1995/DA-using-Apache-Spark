{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 201\n",
    "columns = 2\n",
    "matrix = [[0 for x in range(columns)] for y in range(rows)]\n",
    "# filepath1 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Politics/PoliticsTest/\"\n",
    "# filepath2 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Sports/\"\n",
    "# filepath3 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Business/\"\n",
    "# filepath4 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Movies/\"\n",
    "\n",
    "filepath1 = \"/media/parik/New Volume/DIC/lab3/Lab3-DIC/Lab3-DIC/Politics/\"\n",
    "filepath2 = \"/media/parik/New Volume/DIC/lab3/Lab3-DIC/Lab3-DIC/Sports/\"\n",
    "filepath3 = \"/media/parik/New Volume/DIC/lab3/Lab3-DIC/Lab3-DIC/Business/\"\n",
    "filepath4 = \"/media/parik/New Volume/DIC/lab3/Lab3-DIC/Lab3-DIC/Media/\"\n",
    "\n",
    "\n",
    "filepath11 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Politics/PoliticsTrain/\"\n",
    "filepath21 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Sports/\"\n",
    "filepath31 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Business/\"\n",
    "filepath41 = \"/media/parik/New Volume/DIC/lab3/BigData/P2/Movies/\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from os import listdir\n",
    "strs = [\"\" for x in range(50)]\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "matrix[0][0] = \"Article\"\n",
    "matrix[0][1] = \"Label\"\n",
    "i =1;    \n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "list=[]\n",
    "j=1;\n",
    "for file in os.listdir(filepath1):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath1 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list and len(contents)>0:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>0:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Politics\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break\n",
    "\n",
    "for file in os.listdir(filepath11):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath11 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list and len(contents)>0:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>0:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Politics\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list=[]\n",
    "for file in os.listdir(filepath2):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath2 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>1:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Sports\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break\n",
    "\n",
    "for file in os.listdir(filepath21):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath21 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list and len(contents)>0:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>0:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Sports\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]\n",
    "for file in os.listdir(filepath3):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath3 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>1:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Business\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break\n",
    "\n",
    "for file in os.listdir(filepath31):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath31 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list and len(contents)>0:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>0:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Business\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list=[]\n",
    "for file in os.listdir(filepath4):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath4 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>1:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Movies\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break\n",
    "\n",
    "for file in os.listdir(filepath41):\n",
    "    if file.endswith(\"txt\"):\n",
    "        file = open(filepath41 + file)\n",
    "        contents = file.read()\n",
    "        if contents not in list and len(contents)>0:\n",
    "            list.append(contents)\n",
    "            is_noun = lambda pos: pos[:2] == 'NN'\n",
    "            nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "            c=\"\"\n",
    "            for x in nouns:\n",
    "                c = c+x+\" \"\n",
    "            if len(c)>0:\n",
    "                matrix[j][0] = c\n",
    "                matrix[j][1] = \"Movies\"\n",
    "                j=j+1\n",
    "            if j==50:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# for tfile in os.listdir(filepath2):\n",
    "#     file = open(filepath2+tfile)\n",
    "#     nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "#     c=\"\"\n",
    "#     for x in nouns:\n",
    "#         c = c+x+\" \"\n",
    "#     matrix[i][0] = c\n",
    "#     matrix[i][1] = \"Sports\"\n",
    "#     i = i+1;\n",
    "\n",
    "# for tfile in os.listdir(filepath3):\n",
    "#     file = open(filepath3+tfile)\n",
    "#     nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "#     c=\"\"\n",
    "#     for x in nouns:\n",
    "#         c = c+x+\" \"\n",
    "#     matrix[i][0] = c\n",
    "#     matrix[i][1] = \"Business\"\n",
    "#     i = i+1;\n",
    "\n",
    "# for tfile in os.listdir(filepath4):\n",
    "#     file = open(filepath4+tfile)\n",
    "#     nouns = [word for (word, pos) in nltk.pos_tag(contents.split()) if is_noun(pos)]\n",
    "#     c=\"\"\n",
    "#     for x in nouns:\n",
    "#         c = c+x+\" \"\n",
    "#     matrix[i][0] = c\n",
    "#     matrix[i][1] = \"Movies\"\n",
    "#     i = i+1;\n",
    "    \n",
    "            \n",
    "with open(\"/media/parik/New Volume/DIC/lab3/Final_Data/Final_Data/output.csv\",\"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
