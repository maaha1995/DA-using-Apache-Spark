{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mahalakshmimaddu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "PythonRDD[82] at RDD at PythonRDD.scala:48\n",
      "PythonRDD[90] at RDD at PythonRDD.scala:48\n",
      "PythonRDD[98] at RDD at PythonRDD.scala:48\n",
      "PythonRDD[106] at RDD at PythonRDD.scala:48\n",
      "PythonRDD[114] at RDD at PythonRDD.scala:48\n",
      "[u'sports', u'russia', u'college', u'tax', u'athletes', u'fans', u'book', u'games', u'officials', u'olympic', u'boston', u'world', u'today', u'baseball', u'team', u'way', u'sochi', u'sign', u'kids', u'page']\n",
      "['sports', 'russia', 'college', 'tax', 'athletes', 'fans', 'book', 'games', 'officials', 'olympic', 'boston', 'world', 'today', 'baseball', 'team', 'way', 'sochi', 'sign', 'kids', 'page']\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from operator import add\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"advertisement\")\n",
    "stop_words.add(\"said\")\n",
    "stop_words.add(\"\")\n",
    "stop_words.add(\" \")\n",
    "stop_words.add(\"  \")\n",
    "stop_words.add(\"ms\")\n",
    "stop_words.add(\"house\")\n",
    "stop_words.add(\"brown\")\n",
    "stop_words.add(\"people\")\n",
    "#stop_words.add(\"olympic\")\n",
    "stop_words.add(\"year\")\n",
    "stop_words.add(\"years\")\n",
    "stop_words.add(\"time\")\n",
    "stop_words.add(\"state\")\n",
    "stop_words.add(\"states\")\n",
    "stop_words.add(\"women\")\n",
    "stop_words.add(\"gallon\")\n",
    "stop_words.add(\"juan\")\n",
    "stop_words.add(\"trump\")\n",
    "stop_words.add(\"york\")\n",
    "stop_words.add(\"rico\")\n",
    "stop_words.add(\"puerto\")\n",
    "stop_words.add(\"san\")\n",
    "stop_words.add(\"island\")\n",
    "stop_words.add(\"election\")\n",
    "stop_words.add(\"president\")\n",
    "\n",
    "filepath = \"/Users/mahalakshmimaddu/Desktop/DICLab3/P5/Test_Data/SportsTest/\"\n",
    "\n",
    "for file in os.listdir(filepath):\n",
    "    textRDD = sc.textFile(filepath)\n",
    "    words = textRDD.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1))\n",
    "    print(str(words))\n",
    "    wordcount = words.reduceByKey(add).collect()\n",
    "\n",
    "output = sorted(wordcount, key = lambda x:x[1], reverse=True)\n",
    "\n",
    "top_words = []\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "\n",
    "i = 0;\n",
    "x = 0;\n",
    "\n",
    "while x < len(output) and i < 20:\n",
    "    word = [output[x][0].encode('ascii','ignore')]\n",
    "    if(bool(word[0].strip())):\n",
    "        l1 =  nltk.tag.pos_tag(word)\n",
    "        if ((is_noun(l1[0][1])) and (not (word[0].lower() in (stop_words))) and len(word[0]) > 2):\n",
    "            top_words.append(output[x][0])\n",
    "            i = i+1;\n",
    "            x = x+1;\n",
    "        else:\n",
    "            x = x+1;\n",
    "    else:\n",
    "        x = x+1;\n",
    "print(str(top_words))\n",
    "\n",
    "new_words = []\n",
    "for i in range(len(top_words)):\n",
    "    new_words.append(top_words[i].encode('utf-8'))\n",
    "print(str(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output =['percent', 'business', 'mobile', 'company', 'companies', 'points', 'share', 'sprint', 'stocks', 'facebook', 'businesses', 'deal', 'oil', 'quarter', 'trade', 'apple', 'job', 'industry', 'move', 'twitter', 'movie', 'movies', 'film', 'war', 'lombard', 'creditamy', 'marathon', 'cold', 'liquid', 'scene', 'marvel', 'sky', 'theater', 'water', 'part', 'recommendation', 'pig', 'letter', 'hours', 'theaters', 'president', 'campaign', 'rallies', 'politics', 'art', 'speech', 'news', 'administration', 'man', 'election', 'country', 'something', 'davis', 'crowd', 'told', 'stover', 'rally', 'day', 'week', 'work','sports', 'russia', 'college', 'tax', 'athletes', 'fans', 'book', 'games', 'officials', 'olympic', 'boston', 'world', 'today', 'baseball', 'team', 'way', 'sochi', 'sign', 'kids', 'page'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
